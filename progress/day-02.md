# Day 2 â€” Databricks 14-Day AI Challenge 

Day 2 was all about getting hands-on with Spark DataFrames and understanding how basic transformations work on large datasets.

## What I worked on today 

ğŸ‘‰ Uploaded and loaded a sample e-commerce CSV file into Databricks
ğŸ‘‰Explored the data using display() and select()
ğŸ‘‰Applied filtering logic (price > 100) to understand data distribution
ğŸ‘‰Grouped data by event_type to analyze user behavior (view, cart, purchase)
ğŸ‘‰Identified top 5 brands by event count
ğŸ‘‰Learned how null values impact aggregations and fixed it by excluding them

## Key learnings 

ğŸ‘‰How Spark handles large datasets efficiently using lazy evaluation
ğŸ‘‰Practical use of groupBy, count, orderBy, and limit
ğŸ‘‰Why data cleaning (like handling nulls) is critical before analysis
ğŸ‘‰Difference between raw results vs meaningful insights after filtering

Small steps, but solid foundations in Spark and Databricks 

## Screenshots

![Day 2 screenshot](../assets/day-02/day02_ss1.png)
![Day 2 screenshot](../assets/day-02/day02_ss2.png)
![Day 2 screenshot](../assets/day-02/day02_ss3.png)
![Day 2 screenshot](../assets/day-02/day02_ss4.png)